name: Run PhantomBuster and Upload to S3

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'  # Every 6 hours â€“ adjust as needed

jobs:
  scrape_and_upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install axios and fs
        run: npm install axios fs

      - name: Run PhantomBuster Agent and Save Data
        env:
          PHANTOMBUSTER_API_KEY: ${{ secrets.PHANTOMBUSTER_API_KEY }}
          PHANTOM_AGENT_ID: ${{ secrets.PHANTOM_AGENT_ID }}
        run: |
          node <<EOF
          const axios = require('axios');
          const fs = require('fs');
          
          async function runPhantom() {
            const response = await axios.post(
              \`https://api.phantombuster.com/api/v2/agents/launch\`,
              { id: process.env.PHANTOM_AGENT_ID },
              { headers: { 'X-Phantombuster-Key-1': process.env.PHANTOMBUSTER_API_KEY } }
            );

            const containerId = response.data.containerId;
            console.log("Launched Phantom with Container ID:", containerId);

            // Wait a bit to ensure the phantom finishes and results are available
            await new Promise(r => setTimeout(r, 20000)); // 20 sec wait

            // Download the result
            const resultRes = await axios.get(
              \`https://api.phantombuster.com/api/v2/containers/fetch-output?id=\${containerId}\`,
              { headers: { 'X-Phantombuster-Key-1': process.env.PHANTOMBUSTER_API_KEY } }
            );

            fs.writeFileSync("phantom_result.json", JSON.stringify(resultRes.data, null, 2));
            console.log("Data saved to phantom_result.json");
          }

          runPhantom();
          EOF

      - name: Upload to S3
        uses: jakejarvis/s3-sync-action@master
        with:
          args: --acl public-read --follow-symlinks
        env:
          AWS_S3_BUCKET: ${{ secrets.S3_BUCKET_NAME }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: 'us-east-1' # change if you're using another region
          SOURCE_DIR: '.' # or a subfolder
